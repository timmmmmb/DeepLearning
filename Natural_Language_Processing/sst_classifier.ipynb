{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sst_classifier.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09aa1494899a4bac90e67118d9d270e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68292addf74c4bc8a7a567271c339e07",
            "_dom_classes": [],
            "description": "752500/752937",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 752937,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 752500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f4e3b05b65f4ab0aac06b2c2761895f"
          }
        },
        "68292addf74c4bc8a7a567271c339e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f4e3b05b65f4ab0aac06b2c2761895f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n17XnKcLhCi8",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Classification with a Deep Learning Model\n",
        "\n",
        "This notebook introduces a machine learning task from the field of natural language processing (machine learning focused on the processing of spoken and written text).\n",
        "\n",
        "## Sentiment Analysis\n",
        "\n",
        "The modelled task is a classification task called sentiment analysis. \n",
        "Text snippets are classified according to their positive or negative sentiment that is expressed in them. \n",
        "This can be modelled as 3-class problem (negative, neutral, positive), or as a degree of sentiment on a 5-class or 10-class scale. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Acknowledgement\n",
        "\n",
        "The notebook is based on https://www.manning.com/books/real-world-natural-language-processing, an upcoming book focused on NLP.\n",
        "\n",
        "The ML frameworks used are:\n",
        "\n",
        "* pytorch\n",
        "* allennlp\n",
        "* spacy\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/erikgraf/deepLearning/blob/master/Deep_Learning_Sentiment_classifier.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LqLSgNlhCjC",
        "colab_type": "text"
      },
      "source": [
        "## Installing Dependencies\n",
        "\n",
        "The cell below installs the main dependencies and clones some a repository that forms the basis of the implementation. \n",
        "\n",
        "Executing it with `CTRL + Enter` (`STRG +Enter` on a german keyboard) could take a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WUYWOVTcajS",
        "outputId": "9bad889a-4a25-469d-b190-5a4fa9791068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "!pip install allennlp\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.14.0-cp36-cp36m-linux_x86_64.whl size=3320381 sha256=766ec3f348cab842412b6d228a6f8e47f8a18daf888c7356922bed7b8fdc4d1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/b7/83/985f0f758fbb34f14989a0fab86d18890d1cc5ae12f26967bc\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=7aae33ccc97ca7cfff485ea60e81e67bfc5bfedebc44e3fb7604c34d0c758af8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.8.0-cp36-none-any.whl size=5608 sha256=6d0bdf1c8969ecaf0346aca3813d2a95bda3c897dbfb4ced0a0a5cadc8ad06e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f1/ba/eaf6cd7d284d2f257dc71436ce72d25fd3be5a5813a37794ab\n",
            "Successfully built ftfy word2number numpydoc jsonnet parsimonious overrides\n",
            "Installing collected packages: unidecode, flaky, pytorch-pretrained-bert, ftfy, jsonpickle, responses, word2number, conllu, numpydoc, sentencepiece, pytorch-transformers, jsonnet, parsimonious, tensorboardX, flask-cors, overrides, allennlp\n",
            "Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.6 jsonnet-0.14.0 jsonpickle-1.2 numpydoc-0.9.2 overrides-2.8.0 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.9 sentencepiece-0.1.85 tensorboardX-2.0 unidecode-1.1.1 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbrh-N3hCjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "698a6edb-7fd7-4ec9-ebc5-9a24fec4f36a"
      },
      "source": [
        "!git clone https://github.com/mhagiwara/realworldnlp.git\n",
        "%cd realworldnlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'realworldnlp'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 456 (delta 102), reused 94 (delta 41), pack-reused 288\u001b[K\n",
            "Receiving objects: 100% (456/456), 4.69 MiB | 4.14 MiB/s, done.\n",
            "Resolving deltas: 100% (231/231), done.\n",
            "/content/realworldnlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7vjy8r9hCjg",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Execute the cell below to load all required modules. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FM5pBpj7cajc",
        "colab": {}
      },
      "source": [
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import \\\n",
        "    StanfordSentimentTreeBankDatasetReader\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "from realworldnlp.predictors import SentenceClassifierPredictor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bc39ZQFhCju",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "The cell below sets the hyperparameters.\n",
        "\n",
        "* EMBEDDING_DIM: This is the dimensionality of the word embeddings (numeric representations of words such as word2vec or glove (https://nlp.stanford.edu/projects/glove/))\n",
        "* HIDDEN_DIM: This is the dimensionality of the LSTM (Long Short Term Memory) Deep Learning network. \n",
        "\n",
        "A value of 128 is pretty standard for the embeddings and hidden_dim.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jecKS_nhcajq",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDIUG-RVhCj4",
        "colab_type": "text"
      },
      "source": [
        "## Training Data Set\n",
        "\n",
        "For training we will use the Stanford Sentiment Treebank data set.\n",
        "A data set for training sentiment analysis models. It is annotated both on the sentence and the word level with regard to the sentiment. \n",
        "\n",
        "When loading the data set we can configure the granularity to `'5-class'` or `'3-class'`.\n",
        "\n",
        "`'3-class'` represents classification on the level of `negative`, `neutral`, `positive` encoded as `0`, `1`, `2` (positive). `'5-class'` on a level from `0` to `4`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b-yyKUYxcaj1",
        "colab": {}
      },
      "source": [
        "reader = StanfordSentimentTreeBankDatasetReader(granularity='5-class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N4PBhQZAcaj6",
        "outputId": "5a262fa1-2d09-4cf6-a562-2848b2976538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "train_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/train.txt')\n",
        "dev_dataset = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/dev.txt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/2160058 [00:00<?, ?B/s]\u001b[A\n",
            "  1%|          | 17408/2160058 [00:00<00:20, 102222.18B/s]\u001b[A\n",
            "  2%|▏         | 52224/2160058 [00:00<00:17, 119384.87B/s]\u001b[A\n",
            "  6%|▌         | 121856/2160058 [00:00<00:13, 150893.86B/s]\u001b[A\n",
            " 12%|█▏        | 261120/2160058 [00:00<00:09, 199158.77B/s]\u001b[A\n",
            " 25%|██▍       | 539648/2160058 [00:00<00:06, 269844.27B/s]\u001b[A\n",
            " 52%|█████▏    | 1114112/2160058 [00:01<00:02, 372193.67B/s]\u001b[A\n",
            "8544it [00:04, 2117.30it/s]\n",
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/280825 [00:00<?, ?B/s]\u001b[A\n",
            "  6%|▌         | 17408/280825 [00:00<00:02, 97652.45B/s]\u001b[A\n",
            " 19%|█▊        | 52224/280825 [00:00<00:01, 114368.53B/s]\u001b[A\n",
            " 43%|████▎     | 121856/280825 [00:00<00:01, 145878.61B/s]\u001b[A\n",
            " 87%|████████▋ | 243712/280825 [00:00<00:00, 190530.38B/s]\u001b[A\n",
            "1101it [00:02, 376.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghkt-XdOhCkN",
        "colab_type": "text"
      },
      "source": [
        "## Model Implementation in AllenNLP\n",
        "\n",
        "Execute the cell below to load the model classification.\n",
        "\n",
        "Depending on the class level chosen (3 vs 5) change the positive label in the init method to ('2' or '4').\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5V2kzVAlcajw",
        "colab": {}
      },
      "source": [
        "# Model in AllenNLP represents a model that is trained.\n",
        "@Model.register(\"lstm_classifier\")\n",
        "class LstmClassifier(Model):\n",
        "    def __init__(self,\n",
        "                 word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 vocab: Vocabulary,\n",
        "                 positive_label: str = '4') -> None:\n",
        "        super().__init__(vocab)\n",
        "        # We need the embeddings to convert word IDs to their vector representations\n",
        "        self.word_embeddings = word_embeddings\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # After converting a sequence of vectors to a single vector, we feed it into\n",
        "        # a fully-connected linear layer to reduce the dimension to the total number of labels.\n",
        "        self.linear = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
        "                                      out_features=vocab.get_vocab_size('labels'))\n",
        "\n",
        "        # Monitor the metrics - we use accuracy, as well as prec, rec, f1 for 4 (very positive)\n",
        "        positive_index = vocab.get_token_index(positive_label, namespace='labels')\n",
        "        self.accuracy = CategoricalAccuracy()\n",
        "        self.f1_measure = F1Measure(positive_index)\n",
        "\n",
        "        # We use the cross entropy loss because this is a classification task.\n",
        "        # Note that PyTorch's CrossEntropyLoss combines softmax and log likelihood loss,\n",
        "        # which makes it unnecessary to add a separate softmax layer.\n",
        "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Instances are fed to forward after batching.\n",
        "    # Fields are passed through arguments with the same name.\n",
        "    def forward(self,\n",
        "                tokens: Dict[str, torch.Tensor],\n",
        "                label: torch.Tensor = None) -> torch.Tensor:\n",
        "        # In deep NLP, when sequences of tensors in different lengths are batched together,\n",
        "        # shorter sequences get padded with zeros to make them equal length.\n",
        "        # Masking is the process to ignore extra zeros added by padding\n",
        "        mask = get_text_field_mask(tokens)\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        encoder_out = self.encoder(embeddings, mask)\n",
        "        logits = self.linear(encoder_out)\n",
        "\n",
        "        # In AllenNLP, the output of forward() is a dictionary.\n",
        "        # Your output dictionary must contain a \"loss\" key for your model to be trained.\n",
        "        output = {\"logits\": logits}\n",
        "        if label is not None:\n",
        "            self.accuracy(logits, label)\n",
        "            self.f1_measure(logits, label)\n",
        "            output[\"loss\"] = self.loss_function(logits, label)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        precision, recall, f1_measure = self.f1_measure.get_metric(reset)\n",
        "        return {'accuracy': self.accuracy.get_metric(reset),\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_measure': f1_measure}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbZr7n4nhCkX",
        "colab_type": "text"
      },
      "source": [
        "## Transform Text into Numeric Representation\n",
        "\n",
        "The following cells are responsible for the transformation of text in string form into numeric representations that are suitable as learning input for the neural network.\n",
        "\n",
        "1. Extract vocabulary of unique terms from the text\n",
        "2. Create embeddings for the terms\n",
        "3. Define transformation (encoding) for a sequence of text (i.e. a sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OuchQwj5cakA",
        "outputId": "796465cb-494f-41e4-e4d0-918618954c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# You can optionally specify the minimum count of tokens/labels.\n",
        "# `min_count={'tokens':3}` here means that any tokens that appear less than three times\n",
        "# will be ignored and not included in the vocabulary.\n",
        "vocab = Vocabulary.from_instances(train_dataset + dev_dataset,\n",
        "                                  min_count={'tokens': 3})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9645/9645 [00:00<00:00, 79009.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDx14NvHcakC",
        "colab": {}
      },
      "source": [
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                            embedding_dim=EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VKXSf0wucakG",
        "colab": {}
      },
      "source": [
        "# BasicTextFieldEmbedder takes a dict - we need an embedding just for tokens,\n",
        "# not for labels, which are used as-is as the \"answer\" of the sentence classification\n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93pvAweOcakM",
        "colab": {}
      },
      "source": [
        "# Seq2VecEncoder is a neural network abstraction that takes a sequence of something\n",
        "# (usually a sequence of embedded word vectors), processes it, and returns a single\n",
        "# vector. Oftentimes this is an RNN-based architecture (e.g., LSTM or GRU), but\n",
        "# AllenNLP also supports CNNs and other simple architectures (for example,\n",
        "# just averaging over the input vectors).\n",
        "encoder = PytorchSeq2VecWrapper(\n",
        "    torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCOa1srFhCk4",
        "colab_type": "text"
      },
      "source": [
        "## Configure Model for Training\n",
        "\n",
        "The following four cells configure the model for training.\n",
        "\n",
        "1. The LstmClassifier class takes the word_embeddings, the define sequence encoder and the vocabulary as input configuration. \n",
        "\n",
        "2. The BucketIterator is a helper class for iterating over the full training set and randomly selects batches of instances for the training. \n",
        "\n",
        "3. optimizer specifies the learning rate for Adam (a mathmatical optimisation function that will guide the weight adaptations of our model).\n",
        "\n",
        "4. trainer holds our instatiation of the model, and defines the number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZuuP66iccakR",
        "colab": {}
      },
      "source": [
        "model = LstmClassifier(word_embeddings, encoder, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ip0BO9QecakY",
        "colab": {}
      },
      "source": [
        "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ccuqvd6rcakg",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uu_dBwd1cakk",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(model=model,\n",
        "                  optimizer=optimizer,\n",
        "                  iterator=iterator,\n",
        "                  train_dataset=train_dataset,\n",
        "                  validation_dataset=dev_dataset,\n",
        "                  patience=40,\n",
        "                  num_epochs=40)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6es3sYChClU",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "\n",
        "Execute the cell below to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUs2oVBIhClW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac5b33c0-9a97-4cb2-e72d-6dbe8d44b822"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.2669, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5803 ||: 100%|██████████| 267/267 [00:11<00:00, 24.22it/s]\n",
            "accuracy: 0.2534, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5728 ||: 100%|██████████| 35/35 [00:00<00:00, 122.19it/s]\n",
            "accuracy: 0.2700, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5656 ||: 100%|██████████| 267/267 [00:10<00:00, 26.10it/s]\n",
            "accuracy: 0.2534, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5731 ||: 100%|██████████| 35/35 [00:00<00:00, 122.55it/s]\n",
            "accuracy: 0.2721, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5583 ||: 100%|██████████| 267/267 [00:10<00:00, 25.15it/s]\n",
            "accuracy: 0.2552, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5681 ||: 100%|██████████| 35/35 [00:00<00:00, 136.09it/s]\n",
            "accuracy: 0.2779, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5321 ||: 100%|██████████| 267/267 [00:10<00:00, 25.10it/s]\n",
            "accuracy: 0.2670, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.5606 ||: 100%|██████████| 35/35 [00:00<00:00, 136.46it/s]\n",
            "accuracy: 0.3430, precision: 0.4912, recall: 0.1297, f1_measure: 0.2052, loss: 1.4696 ||: 100%|██████████| 267/267 [00:10<00:00, 25.44it/s]\n",
            "accuracy: 0.3252, precision: 0.3425, recall: 0.1515, f1_measure: 0.2101, loss: 1.5628 ||: 100%|██████████| 35/35 [00:00<00:00, 131.22it/s]\n",
            "accuracy: 0.4382, precision: 0.4653, recall: 0.4837, f1_measure: 0.4743, loss: 1.3635 ||: 100%|██████████| 267/267 [00:10<00:00, 24.90it/s]\n",
            "accuracy: 0.3488, precision: 0.2872, recall: 0.3273, f1_measure: 0.3059, loss: 1.5249 ||: 100%|██████████| 35/35 [00:00<00:00, 125.48it/s]\n",
            "accuracy: 0.5036, precision: 0.5310, recall: 0.6242, f1_measure: 0.5739, loss: 1.2230 ||: 100%|██████████| 267/267 [00:10<00:00, 25.08it/s]\n",
            "accuracy: 0.3397, precision: 0.3485, recall: 0.4182, f1_measure: 0.3802, loss: 1.5205 ||: 100%|██████████| 35/35 [00:00<00:00, 137.47it/s]\n",
            "accuracy: 0.5558, precision: 0.6128, recall: 0.6980, f1_measure: 0.6526, loss: 1.0968 ||: 100%|██████████| 267/267 [00:10<00:00, 24.82it/s]\n",
            "accuracy: 0.3551, precision: 0.3596, recall: 0.4424, f1_measure: 0.3967, loss: 1.5076 ||: 100%|██████████| 35/35 [00:00<00:00, 137.21it/s]\n",
            "accuracy: 0.6023, precision: 0.6861, recall: 0.7415, f1_measure: 0.7127, loss: 0.9822 ||: 100%|██████████| 267/267 [00:10<00:00, 24.79it/s]\n",
            "accuracy: 0.3778, precision: 0.4074, recall: 0.4000, f1_measure: 0.4037, loss: 1.6284 ||: 100%|██████████| 35/35 [00:00<00:00, 130.53it/s]\n",
            "accuracy: 0.6392, precision: 0.7292, recall: 0.7966, f1_measure: 0.7614, loss: 0.8945 ||: 100%|██████████| 267/267 [00:10<00:00, 25.13it/s]\n",
            "accuracy: 0.3778, precision: 0.3976, recall: 0.4000, f1_measure: 0.3988, loss: 1.6290 ||: 100%|██████████| 35/35 [00:00<00:00, 134.68it/s]\n",
            "accuracy: 0.6668, precision: 0.7525, recall: 0.8121, f1_measure: 0.7812, loss: 0.8282 ||: 100%|██████████| 267/267 [00:10<00:00, 25.10it/s]\n",
            "accuracy: 0.3633, precision: 0.3991, recall: 0.5273, f1_measure: 0.4543, loss: 1.6371 ||: 100%|██████████| 35/35 [00:00<00:00, 133.25it/s]\n",
            "accuracy: 0.6896, precision: 0.7675, recall: 0.8509, f1_measure: 0.8071, loss: 0.7659 ||: 100%|██████████| 267/267 [00:10<00:00, 24.30it/s]\n",
            "accuracy: 0.3697, precision: 0.3989, recall: 0.4424, f1_measure: 0.4195, loss: 1.8449 ||: 100%|██████████| 35/35 [00:00<00:00, 125.71it/s]\n",
            "accuracy: 0.7129, precision: 0.7968, recall: 0.8587, f1_measure: 0.8266, loss: 0.7077 ||: 100%|██████████| 267/267 [00:10<00:00, 22.01it/s]\n",
            "accuracy: 0.3460, precision: 0.3441, recall: 0.3879, f1_measure: 0.3647, loss: 1.9481 ||: 100%|██████████| 35/35 [00:00<00:00, 127.91it/s]\n",
            "accuracy: 0.7411, precision: 0.8237, recall: 0.8890, f1_measure: 0.8551, loss: 0.6576 ||: 100%|██████████| 267/267 [00:10<00:00, 24.67it/s]\n",
            "accuracy: 0.3497, precision: 0.3539, recall: 0.3818, f1_measure: 0.3673, loss: 2.1054 ||: 100%|██████████| 35/35 [00:00<00:00, 127.17it/s]\n",
            "accuracy: 0.7519, precision: 0.8412, recall: 0.9006, f1_measure: 0.8699, loss: 0.6289 ||: 100%|██████████| 267/267 [00:10<00:00, 24.68it/s]\n",
            "accuracy: 0.3379, precision: 0.3293, recall: 0.3333, f1_measure: 0.3313, loss: 2.1264 ||: 100%|██████████| 35/35 [00:00<00:00, 132.99it/s]\n",
            "accuracy: 0.7711, precision: 0.8592, recall: 0.9099, f1_measure: 0.8839, loss: 0.5808 ||: 100%|██████████| 267/267 [00:10<00:00, 25.20it/s]\n",
            "accuracy: 0.3315, precision: 0.3333, recall: 0.3515, f1_measure: 0.3422, loss: 2.2689 ||: 100%|██████████| 35/35 [00:00<00:00, 131.05it/s]\n",
            "accuracy: 0.7831, precision: 0.8785, recall: 0.9262, f1_measure: 0.9017, loss: 0.5489 ||: 100%|██████████| 267/267 [00:10<00:00, 26.63it/s]\n",
            "accuracy: 0.3433, precision: 0.3457, recall: 0.3394, f1_measure: 0.3425, loss: 2.4671 ||: 100%|██████████| 35/35 [00:00<00:00, 136.98it/s]\n",
            "accuracy: 0.7915, precision: 0.8606, recall: 0.9154, f1_measure: 0.8871, loss: 0.5315 ||: 100%|██████████| 267/267 [00:10<00:00, 27.76it/s]\n",
            "accuracy: 0.3361, precision: 0.3446, recall: 0.3697, f1_measure: 0.3567, loss: 2.5183 ||: 100%|██████████| 35/35 [00:00<00:00, 127.18it/s]\n",
            "accuracy: 0.8110, precision: 0.8919, recall: 0.9286, f1_measure: 0.9099, loss: 0.4916 ||: 100%|██████████| 267/267 [00:10<00:00, 25.22it/s]\n",
            "accuracy: 0.3333, precision: 0.3691, recall: 0.3333, f1_measure: 0.3503, loss: 2.5079 ||: 100%|██████████| 35/35 [00:00<00:00, 137.09it/s]\n",
            "accuracy: 0.8222, precision: 0.8996, recall: 0.9325, f1_measure: 0.9157, loss: 0.4621 ||: 100%|██████████| 267/267 [00:10<00:00, 25.05it/s]\n",
            "accuracy: 0.3324, precision: 0.3541, recall: 0.4485, f1_measure: 0.3957, loss: 2.6278 ||: 100%|██████████| 35/35 [00:00<00:00, 131.15it/s]\n",
            "accuracy: 0.8275, precision: 0.9038, recall: 0.9262, f1_measure: 0.9149, loss: 0.4523 ||: 100%|██████████| 267/267 [00:10<00:00, 25.00it/s]\n",
            "accuracy: 0.3306, precision: 0.3483, recall: 0.3758, f1_measure: 0.3615, loss: 2.8658 ||: 100%|██████████| 35/35 [00:00<00:00, 134.50it/s]\n",
            "accuracy: 0.8379, precision: 0.9048, recall: 0.9441, f1_measure: 0.9240, loss: 0.4246 ||: 100%|██████████| 267/267 [00:10<00:00, 25.02it/s]\n",
            "accuracy: 0.3342, precision: 0.3478, recall: 0.3879, f1_measure: 0.3668, loss: 2.9501 ||: 100%|██████████| 35/35 [00:00<00:00, 133.59it/s]\n",
            "accuracy: 0.8482, precision: 0.9101, recall: 0.9433, f1_measure: 0.9264, loss: 0.4055 ||: 100%|██████████| 267/267 [00:10<00:00, 24.55it/s]\n",
            "accuracy: 0.3379, precision: 0.3503, recall: 0.3758, f1_measure: 0.3626, loss: 2.9725 ||: 100%|██████████| 35/35 [00:00<00:00, 130.36it/s]\n",
            "accuracy: 0.8558, precision: 0.9199, recall: 0.9457, f1_measure: 0.9326, loss: 0.3883 ||: 100%|██████████| 267/267 [00:10<00:00, 29.46it/s]\n",
            "accuracy: 0.3351, precision: 0.3250, recall: 0.3939, f1_measure: 0.3562, loss: 3.2309 ||: 100%|██████████| 35/35 [00:00<00:00, 132.20it/s]\n",
            "accuracy: 0.8563, precision: 0.9072, recall: 0.9410, f1_measure: 0.9238, loss: 0.3862 ||: 100%|██████████| 267/267 [00:10<00:00, 24.72it/s]\n",
            "accuracy: 0.3215, precision: 0.3140, recall: 0.3273, f1_measure: 0.3205, loss: 3.3446 ||: 100%|██████████| 35/35 [00:00<00:00, 133.86it/s]\n",
            "accuracy: 0.8679, precision: 0.9241, recall: 0.9550, f1_measure: 0.9393, loss: 0.3574 ||: 100%|██████████| 267/267 [00:10<00:00, 25.07it/s]\n",
            "accuracy: 0.3297, precision: 0.3314, recall: 0.3394, f1_measure: 0.3353, loss: 3.2557 ||: 100%|██████████| 35/35 [00:00<00:00, 134.55it/s]\n",
            "accuracy: 0.8768, precision: 0.9297, recall: 0.9550, f1_measure: 0.9422, loss: 0.3464 ||: 100%|██████████| 267/267 [00:10<00:00, 24.38it/s]\n",
            "accuracy: 0.3388, precision: 0.3373, recall: 0.3394, f1_measure: 0.3384, loss: 3.4646 ||: 100%|██████████| 35/35 [00:00<00:00, 130.75it/s]\n",
            "accuracy: 0.8798, precision: 0.9264, recall: 0.9581, f1_measure: 0.9420, loss: 0.3326 ||: 100%|██████████| 267/267 [00:10<00:00, 24.72it/s]\n",
            "accuracy: 0.3388, precision: 0.3588, recall: 0.3697, f1_measure: 0.3642, loss: 3.5331 ||: 100%|██████████| 35/35 [00:00<00:00, 124.39it/s]\n",
            "accuracy: 0.8837, precision: 0.9342, recall: 0.9596, f1_measure: 0.9468, loss: 0.3281 ||: 100%|██████████| 267/267 [00:10<00:00, 24.54it/s]\n",
            "accuracy: 0.3279, precision: 0.3333, recall: 0.3515, f1_measure: 0.3422, loss: 3.4803 ||: 100%|██████████| 35/35 [00:00<00:00, 137.45it/s]\n",
            "accuracy: 0.8868, precision: 0.9264, recall: 0.9581, f1_measure: 0.9420, loss: 0.3155 ||: 100%|██████████| 267/267 [00:10<00:00, 24.69it/s]\n",
            "accuracy: 0.3488, precision: 0.3242, recall: 0.3576, f1_measure: 0.3401, loss: 3.7497 ||: 100%|██████████| 35/35 [00:00<00:00, 132.55it/s]\n",
            "accuracy: 0.8982, precision: 0.9415, recall: 0.9620, f1_measure: 0.9516, loss: 0.2917 ||: 100%|██████████| 267/267 [00:10<00:00, 27.25it/s]\n",
            "accuracy: 0.3406, precision: 0.3442, recall: 0.3212, f1_measure: 0.3323, loss: 3.8110 ||: 100%|██████████| 35/35 [00:00<00:00, 134.15it/s]\n",
            "accuracy: 0.9016, precision: 0.9393, recall: 0.9612, f1_measure: 0.9501, loss: 0.2867 ||: 100%|██████████| 267/267 [00:10<00:00, 24.56it/s]\n",
            "accuracy: 0.3415, precision: 0.3446, recall: 0.3091, f1_measure: 0.3259, loss: 3.8613 ||: 100%|██████████| 35/35 [00:00<00:00, 131.84it/s]\n",
            "accuracy: 0.9037, precision: 0.9306, recall: 0.9573, f1_measure: 0.9437, loss: 0.2784 ||: 100%|██████████| 267/267 [00:10<00:00, 25.78it/s]\n",
            "accuracy: 0.3361, precision: 0.3436, recall: 0.3394, f1_measure: 0.3415, loss: 3.9181 ||: 100%|██████████| 35/35 [00:00<00:00, 134.45it/s]\n",
            "accuracy: 0.9161, precision: 0.9505, recall: 0.9697, f1_measure: 0.9600, loss: 0.2493 ||: 100%|██████████| 267/267 [00:10<00:00, 24.35it/s]\n",
            "accuracy: 0.3361, precision: 0.3393, recall: 0.3455, f1_measure: 0.3423, loss: 3.9973 ||: 100%|██████████| 35/35 [00:00<00:00, 136.87it/s]\n",
            "accuracy: 0.9182, precision: 0.9550, recall: 0.9713, f1_measure: 0.9630, loss: 0.2413 ||: 100%|██████████| 267/267 [00:10<00:00, 24.47it/s]\n",
            "accuracy: 0.3279, precision: 0.3295, recall: 0.3515, f1_measure: 0.3402, loss: 4.0651 ||: 100%|██████████| 35/35 [00:00<00:00, 134.51it/s]\n",
            "accuracy: 0.9225, precision: 0.9580, recall: 0.9744, f1_measure: 0.9661, loss: 0.2336 ||: 100%|██████████| 267/267 [00:10<00:00, 24.72it/s]\n",
            "accuracy: 0.3397, precision: 0.3353, recall: 0.3394, f1_measure: 0.3373, loss: 4.2223 ||: 100%|██████████| 35/35 [00:00<00:00, 133.18it/s]\n",
            "accuracy: 0.9238, precision: 0.9573, recall: 0.9744, f1_measure: 0.9658, loss: 0.2258 ||: 100%|██████████| 267/267 [00:10<00:00, 24.94it/s]\n",
            "accuracy: 0.3306, precision: 0.3354, recall: 0.3333, f1_measure: 0.3343, loss: 4.2614 ||: 100%|██████████| 35/35 [00:00<00:00, 128.34it/s]\n",
            "accuracy: 0.9272, precision: 0.9584, recall: 0.9666, f1_measure: 0.9625, loss: 0.2160 ||: 100%|██████████| 267/267 [00:10<00:00, 24.36it/s]\n",
            "accuracy: 0.3388, precision: 0.3473, recall: 0.3515, f1_measure: 0.3494, loss: 4.2799 ||: 100%|██████████| 35/35 [00:00<00:00, 130.86it/s]\n",
            "accuracy: 0.9272, precision: 0.9480, recall: 0.9620, f1_measure: 0.9549, loss: 0.2216 ||: 100%|██████████| 267/267 [00:10<00:00, 24.90it/s]\n",
            "accuracy: 0.3342, precision: 0.3448, recall: 0.3636, f1_measure: 0.3540, loss: 4.2871 ||: 100%|██████████| 35/35 [00:00<00:00, 126.66it/s]\n",
            "accuracy: 0.9307, precision: 0.9543, recall: 0.9728, f1_measure: 0.9635, loss: 0.2105 ||: 100%|██████████| 267/267 [00:10<00:00, 24.64it/s]\n",
            "accuracy: 0.3333, precision: 0.3562, recall: 0.3455, f1_measure: 0.3508, loss: 4.4227 ||: 100%|██████████| 35/35 [00:00<00:00, 132.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 7,\n",
              " 'best_validation_accuracy': 0.35513169845594916,\n",
              " 'best_validation_f1_measure': 0.39673912525177,\n",
              " 'best_validation_loss': 1.5076080935341971,\n",
              " 'best_validation_precision': 0.35960590839385986,\n",
              " 'best_validation_recall': 0.4424242377281189,\n",
              " 'epoch': 39,\n",
              " 'peak_cpu_memory_MB': 580.26,\n",
              " 'peak_gpu_0_memory_MB': 10,\n",
              " 'training_accuracy': 0.9307116104868914,\n",
              " 'training_cpu_memory_MB': 580.26,\n",
              " 'training_duration': '0:07:22.532938',\n",
              " 'training_epochs': 39,\n",
              " 'training_f1_measure': 0.9634755253791809,\n",
              " 'training_gpu_0_memory_MB': 10,\n",
              " 'training_loss': 0.2105061358838492,\n",
              " 'training_precision': 0.9543031454086304,\n",
              " 'training_recall': 0.9728260636329651,\n",
              " 'training_start_epoch': 0,\n",
              " 'validation_accuracy': 0.3333333333333333,\n",
              " 'validation_f1_measure': 0.3507692217826843,\n",
              " 'validation_loss': 4.422715268816266,\n",
              " 'validation_precision': 0.35624998807907104,\n",
              " 'validation_recall': 0.34545454382896423}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BBy3vy0hCld",
        "colab_type": "text"
      },
      "source": [
        "## Sanity Check\n",
        "\n",
        "The cell below will allow you to enter sample sentences and test the predictions of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oxRELM_-cako",
        "outputId": "7d4c2792-670a-4087-8190-e95983e5f9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictor = SentenceClassifierPredictor(model, dataset_reader=reader)\n",
        "logits = predictor.predict(\"Don't waste your money\")['logits']\n",
        "label_id = np.argmax(logits)\n",
        "\n",
        "print(model.vocab.get_token_from_index(label_id, 'labels'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMj09a0hCll",
        "colab_type": "text"
      },
      "source": [
        "## More Substantive Checks\n",
        "\n",
        "In order to do some more in depth checks how well the model does, and how well it might generalize we can utilize a set of Amazon reviews. \n",
        "\n",
        "http://jmcauley.ucsd.edu/data/amazon/\n",
        "\n",
        "The site above holds a very large of Amazon reviews that can be used for scientific purposes. \n",
        "\n",
        "### Task 1: Choose and Download a Subcategory\n",
        "\n",
        "From the table below, choose a category that you will use for testing. \n",
        "Download the 5 core links that hold the full text, title and rating of a review. \n",
        "\n",
        "\n",
        "<html>\n",
        "\n",
        "<table>\n",
        "<tbody><tr>\n",
        "  <td>Books</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_10.json.gz\">10-core</a> (4,701,968 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz\">5-core</a> (8,898,041 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Books.csv\">ratings only</a> (22,507,155 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Electronics</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_10.json.gz\">10-core</a> (347,393 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\">5-core</a> (1,689,188 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Electronics.csv\">ratings only</a> (7,824,482 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Movies and TV</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_10.json.gz\">10-core</a> (958,986 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz\">5-core</a> (1,697,533 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Movies_and_TV.csv\">ratings only</a> (4,607,047 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>CDs and Vinyl</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_CDs_and_Vinyl_10.json.gz\">10-core</a> (445,412 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_CDs_and_Vinyl_5.json.gz\">5-core</a> (1,097,592 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_CDs_and_Vinyl.csv\">ratings only</a> (3,749,004 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Clothing, Shoes and Jewelry</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Clothing_Shoes_and_Jewelry_5.json.gz\">5-core</a> (278,677 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Clothing_Shoes_and_Jewelry.csv\">ratings only</a> (5,748,920 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Home and Kitchen</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_10.json.gz\">10-core</a> (25,445 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Home_and_Kitchen_5.json.gz\">5-core</a> (551,682 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Home_and_Kitchen.csv\">ratings only</a> (4,253,926 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Kindle Store</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_10.json.gz\">10-core</a> (367,478 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz\">5-core</a> (982,619 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Kindle_Store.csv\">ratings only</a> (3,205,467 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Sports and Outdoors</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\">5-core</a> (296,337 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Sports_and_Outdoors.csv\">ratings only</a> (3,268,695 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Cell Phones and Accessories</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_10.json.gz\">10-core</a> (1,854 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\">5-core</a> (194,439 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Cell_Phones_and_Accessories.csv\">ratings only</a> (3,447,249 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Health and Personal Care</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Health_and_Personal_Care_10.json.gz\">10-core</a> (55,076 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Health_and_Personal_Care_5.json.gz\">5-core</a> (346,355 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Health_and_Personal_Care.csv\">ratings only</a> (2,982,326 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Toys and Games</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Toys_and_Games_10.json.gz\">10-core</a> (18,637 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Toys_and_Games_5.json.gz\">5-core</a> (167,597 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Toys_and_Games.csv\">ratings only</a> (2,252,771 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Video Games</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_10.json.gz\">10-core</a> (52,158 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz\">5-core</a> (231,780 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Video_Games.csv\">ratings only</a> (1,324,753 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Tools and Home Improvement</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Tools_and_Home_Improvement_5.json.gz\">5-core</a> (134,476 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Tools_and_Home_Improvement.csv\">ratings only</a> (1,926,047 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Beauty</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Beauty_10.json.gz\">10-core</a> (28,798 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Beauty_5.json.gz\">5-core</a> (198,502 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Beauty.csv\">ratings only</a> (2,023,070 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Apps for Android</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_10.json.gz\">10-core</a> (264,050 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz\">5-core</a> (752,937 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Apps_for_Android.csv\">ratings only</a> (2,638,172 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Office Products</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_10.json.gz\">10-core</a> (25,374 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\">5-core</a> (53,258 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Office_Products.csv\">ratings only</a> (1,243,186 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Pet Supplies</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Pet_Supplies_10.json.gz\">10-core</a> (3,152 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Pet_Supplies_5.json.gz\">5-core</a> (157,836 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Pet_Supplies.csv\">ratings only</a> (1,235,316 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Automotive</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Automotive_5.json.gz\">5-core</a> (20,473 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Automotive.csv\">ratings only</a> (1,373,768 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Grocery and Gourmet Food</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Grocery_and_Gourmet_Food_10.json.gz\">10-core</a> (37,348 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Grocery_and_Gourmet_Food_5.json.gz\">5-core</a> (151,254 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Grocery_and_Gourmet_Food.csv\">ratings only</a> (1,297,156 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Patio, Lawn and Garden</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Patio_Lawn_and_Garden_5.json.gz\">5-core</a> (13,272 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Patio_Lawn_and_Garden.csv\">ratings only</a> (993,490 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Baby</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Baby_5.json.gz\">5-core</a> (160,792 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Baby.csv\">ratings only</a> (915,446 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Digital Music</td>\n",
        "  <!-- <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Digital_Music_10.json.gz\">10-core</a> (22,772 reviews)</td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Digital_Music_5.json.gz\">5-core</a> (64,706 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Digital_Music.csv\">ratings only</a> (836,006 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Musical Instruments</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\">5-core</a> (10,261 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Musical_Instruments.csv\">ratings only</a> (500,176 ratings)</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "  <td>Amazon Instant Video</td>\n",
        "  <!-- <td></td> -->\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Instant_Video_5.json.gz\">5-core</a> (37,126 reviews)</td>\n",
        "  <td><a href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Amazon_Instant_Video.csv\">ratings only</a> (583,933 ratings)</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "    </table>\n",
        "</html>\n",
        "\n",
        "### Task 2\n",
        "\n",
        "Sanity checks with the reviews.\n",
        "\n",
        "The format of the files is as follows:\n",
        "\n",
        "`{\n",
        "\t\"reviewerID\": \"A2ICI6VUC0U5K6\",\n",
        "\t\"asin\": \"B0014JKKGK\",\n",
        "\t\"reviewerName\": \"Jermin Botrous \\\"gigigigi\\\"\",\n",
        "\t\"helpful\": [0, 0],\n",
        "\t\"reviewText\": \"Don't waste your money because elastic goes bad after 2 washes\",\n",
        "\t\"overall\": 1.0,\n",
        "\t\"summary\": \"One Star\",\n",
        "\t\"unixReviewTime\": 1404432000,\n",
        "\t\"reviewTime\": \"07 4, 2014\"\n",
        "}`\n",
        "\n",
        "Use the following code snippets to load individal review texts.\n",
        "\n",
        "Opening a file in python:\n",
        "\n",
        "``\n",
        "test_file = open('file_name.json', 'r')\n",
        "first_line = test_file.readline()\n",
        "``\n",
        "\n",
        "Transform the line into a json object to access the individual fiels (such as reviewText).\n",
        "\n",
        "\n",
        "``\n",
        "import json\n",
        "j_obj = json.loads(first_line)\n",
        "print('reviewText:' + j_obj['reviewText'])\n",
        "``\n",
        "\n",
        "finally use the code from above to test the predictions\n",
        "\n",
        "``\n",
        "logits = predictor.predict(\"Don't waste your money\")['logits']\n",
        "label_id = np.argmax(logits)\n",
        "prediction = model.vocab.get_token_from_index(label_id, 'labels')\n",
        "print(prediction)\n",
        "``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDpSRw89hClm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Apps_for_Android_5.json.gz\n",
        "!gunzip reviews_Apps_for_Android_5.json.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxumhffyhnml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "14830d90-e7d0-449e-e83f-eeeee15296a5"
      },
      "source": [
        "import json\n",
        "\n",
        "test_file = open('reviews_Apps_for_Android_5.json', 'r')\n",
        "lines = test_file.readlines()\n",
        "first_line = lines[0]\n",
        "print('first_line:', first_line, end='')\n",
        "\n",
        "def get_review_text(line):\n",
        "  return json.loads(line)['reviewText']\n",
        "\n",
        "review_text = get_review_text(first_line)\n",
        "print('review_text:', review_text)\n",
        "\n",
        "\n",
        "def predict(text):\n",
        "  logits = predictor.predict(text)['logits']\n",
        "  label_id = np.argmax(logits)\n",
        "  prediction = model.vocab.get_token_from_index(label_id, 'labels')\n",
        "  return int(prediction)\n",
        "\n",
        "prediction = predict(review_text)\n",
        "print('prediction:', prediction)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_line: {\"reviewerID\": \"A1N4O8VOJZTDVB\", \"asin\": \"B004A9SDD8\", \"reviewerName\": \"Annette Yancey\", \"helpful\": [1, 1], \"reviewText\": \"Loves the song, so he really couldn't wait to play this. A little less interesting for him so he doesn't play long, but he is almost 3 and likes to play the older games, but really cute for a younger child.\", \"overall\": 3.0, \"summary\": \"Really cute\", \"unixReviewTime\": 1383350400, \"reviewTime\": \"11 2, 2013\"}\n",
            "review_text: Loves the song, so he really couldn't wait to play this. A little less interesting for him so he doesn't play long, but he is almost 3 and likes to play the older games, but really cute for a younger child.\n",
            "prediction: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpsIXfZehClt",
        "colab_type": "text"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Iterate over the reviews and extract:\n",
        "\n",
        "* 100 positive predictions (i.e. 4)\n",
        "* 100 negative predictions (i.e. 0)\n",
        "\n",
        "Save the sets of positive and negative predictions as plain text files:\n",
        "\n",
        "* categoryName_100_pos.txt\n",
        "* categoryName_100_neg.txt\n",
        "\n",
        "Manually inspect the predictions to identify potential false positives in boths sets.\n",
        "Store a couple of those false positives in the files:\n",
        "\n",
        "* categoryName_100_pos_fp.txt\n",
        "* categoryName_100_neg_fp.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlVoGN1QhCly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "dd712289-67dc-45b4-919b-31bb3052d569"
      },
      "source": [
        "positive_predictions = []\n",
        "negative_predictions = []\n",
        "\n",
        "for line in lines:\n",
        "  text = get_review_text(line)\n",
        "  prediction = predict(text)\n",
        "\n",
        "  if prediction == 0:\n",
        "    negative_predictions.append(text)\n",
        "  elif prediction == 4:\n",
        "    positive_predictions.append(text)\n",
        "\n",
        "  if len(positive_predictions) >= 100 and len(negative_predictions) >= 100:\n",
        "    break\n",
        "\n",
        "print('Positive samples:')\n",
        "print('\\n'.join(positive_predictions[0:10]))\n",
        "\n",
        "print('\\nNegative samples:')\n",
        "print('\\n'.join(negative_predictions[0:10]))\n",
        "\n",
        "def save_samples(file_name, samples):\n",
        "  with open(file_name, 'w') as file_:\n",
        "    file_.write('\\n'.join(samples))\n",
        "\n",
        "save_samples('AppsForAndroid_100_pos.txt', positive_predictions[0:100])\n",
        "save_samples('AppsForAndroid_100_neg.txt', negative_predictions[0:100])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples:\n",
            "I watch my great grandson 4 days a week and it's hard to keep a 16 month old occupied but all I have to do is turn on Five Little Monkeys and he goes crazy trying to get the monkey's off the bed and touching all the other interactive things on the screen. I love this! I absolutely recommend this!\n",
            "Good for little ones, especially if  know the nursery rhyme.  Once you show them what to click on they pick it up fast.\n",
            "Great selections.  Easy to use interface.  I have playlists for everyone in the family (me, hubby, and 10 year old son).  Works great on the PC and my MP3 players (no Apple products tested).  Also use with Sonos and that interface is also simple to use.Only complaint is that you can't customize your plan.  I want 2 MP3 players and I'd have to pay for 3.  It's an extra $70 a year.  I would only pay $2 a month for the second player, so I got a huge capacity MP3 and share.  Easy to do with playlists.\n",
            "I really don't think I could live without Rhapsody. I have it on my phone, my computer and my Kindle Fire. I use it everyday, no matter what device it is on, it works great. It is a wonderful way to take your favorite music and playlists with you wherever you go, whatever you do. Be aware that you do have to have a subscription and I'm pretty sure the price can range from $10 and up per month.\n",
            "I love this app!! Yes,after 14 days you have to pay $9.99 a month....but this app has helped keep my sanity. It is the first app that Amazon has put out for music that I have liked. I  have tried over 100 apps. from Amazon and they asked for my opinion....here it is.Rhaspody has an extremely large array of music.I had no problem finding all the different artists and albums that I love. You can even download music to play off- line . I can listen to my music all day and night long.Please get this app....you,ll love it!\n",
            "If you pay for the subscription then by all meens get this App. It works well and  I love the service. I have a family of 4 and we all use it under one price.\n",
            "I have been a Rhapsody susbscriber for many years.  The service has been reliable and a good value, but the latest smartphone and tablet apps take it to a new level.  The UI is much improved, intuative, and brings recommendations and new releases once available only on the desktop software.  Good work!\n",
            "I love my rhapsody!! I was so glad that I could get it on my kindle for my daughter!! I have had Rhapsody since it was Napster...love that it is a device that we can use it on!\n",
            "Rhapsody is great if you like \"All you can Eat\" music..  There are a lot of music programs and services out there now but I always come back to Rhapsody for a couple reasons.1.) I love their desktop app!!2.) I love being able to use the service with a REAL mp3 player, not just an android phone or ipod touch/iphone.  With the desktop app, the service works with Sandisk MP3 Players (Most are supported but check rhapsody before you purchase one)Now for this app.  The app on android and Kindle is great.  It gives you access, not just to their radio feature, but also to their \"all you can eat\" music service.  You can download the tracks to your phone for free (As long as you keep paying the monthly fee, these songs stay active\".  Their \"radio\" feature is great if you like services like Pandora.  The Rhapsody radio doesn't have the ads like Pandora and other free radio services.  The radio feature is also very smart just like Pandora (Though I would say it is not as smart as Pandora).Overall this is a great app if you like music and like being able to choose what songs you want to listen to or if you wanna listen to an entire album!!  And the app doesn't bog the phone down with adds or video adds like Pandora!Try it for a month!! Most new phones and kindles will give you a free trial! If not you can use this link for one.. I was one over with the free trial I received when I downloaded this app to my Kindle[...]\n",
            "It allows me to access Rhapsody on my Kindle which I would not be able to do without the app.\n",
            "\n",
            "Negative samples:\n",
            "Tried to run this on my Kindle Fire; kept giving me message that I needed an updated flash player. When I tried to download, there were several selections, but none seemed to match my Kindle Fire settings and the ones I tried to download, didn't make Rhapsody work either. There seemed to be two ways to access Rhapsody; one took me to all this problem of the download and the other was the pay for it monthly option. I deleted all the downloads & Rhapsody app off my Kindle.\n",
            "I have been a therapist fan for years. it' s a great product. download as many songs as you want each month. super quick and easy. affordable.\n",
            "Ipad and Ipod Touch versions are much better. App can be hard to navigate at times and seems more like a mobile site than a convenient app.\n",
            "why would you want to get a free app and but then have to pay 10 bucks a month to use it?\n",
            "wanted to find a music app that was free this one was not and was way too much money for what I was looking for.\n",
            "I got a new Kindle and quickly started downloading a bunch of apps and books.  I downloaded this app and realized it wasn&#8217;t for me.  It bored me very quickly.  I downloaded the important ones from Amazon&#8217;s library and am content with what I have.  Not for me&#8230;but maybe you&#8217;ll like it.\n",
            "Excellent source for music if your  willing to pay for the service.  If you're looking for music give it a try, they give you a free trail. If you don't like it you can always look elsewhere.\n",
            "Went looking for a app to listen to tunes on my Kindle fire.Tried a few free app,not my cup of tea).Like this 1 cause I don't have to take up a lot of space on my device.\n",
            "I have used this music source for a number of years and overall, they have a good variety ranging from Jack Hylton to Frank Sinatra to Black Ghosts. The only problem I had is that I had to keep the Caffine app on in order to get more than 30 seconds of a song which I found a little frustrating.  Still, a great way to hear some music from yesteryear and expand on your interests!\n",
            "Soo much easier than downloading music. I don't care about the 10 bux a month subscription. I get to listen to anything from comedy cd's by kevin hart, wheels on the bus for my son or the first beastie boys cd. It has everything.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UXaJi9vhCl2",
        "colab_type": "text"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "Generate listing of false positives.\n",
        "Analyse the data from Amazon.\n",
        "What would be a way to utilize this data in order to generate larger lists of false positives?\n",
        "Derive a method that will allow you to predict over the full content of the file and create lists of:\n",
        "* True positive 'positive' predictions\n",
        "* False positive 'positive' predictions\n",
        "* True positive 'negative' predictions\n",
        "* False positive 'negative' predictions\n",
        "\n",
        "Save the four sets four your group submission:\n",
        "\n",
        "* categoryName_pos_tp.txt\n",
        "* categoryName_pos_fp.txt\n",
        "* categoryName_neg_tp.txt\n",
        "* categoryName_neg_fp.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuUaGNvPhCl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "09aa1494899a4bac90e67118d9d270e1",
            "68292addf74c4bc8a7a567271c339e07",
            "8f4e3b05b65f4ab0aac06b2c2761895f"
          ]
        },
        "outputId": "4d566c83-eb38-4b26-82b3-d0587066645c"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "progress = widgets.IntProgress(value=0, min=0, max=len(lines), step=1)\n",
        "display(progress)\n",
        "\n",
        "true_positives = []\n",
        "false_positives = []\n",
        "true_negatives = []\n",
        "false_negatives = []\n",
        "\n",
        "def parse_review(line):\n",
        "  dict_ = json.loads(line)\n",
        "  return (dict_['reviewText'], dict_[\"overall\"])\n",
        "\n",
        "for index, line in enumerate(lines):\n",
        "  if index % 500 == 0:\n",
        "    progress.value = index\n",
        "    progress.description = str(index) + '/' + str(len(lines))\n",
        "\n",
        "  try:\n",
        "    text, rating = parse_review(line)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  # Only use clear ratings for now\n",
        "  if rating == 3.0:\n",
        "    continue\n",
        "\n",
        "  try:\n",
        "    prediction = predict(text)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  actually_positive = rating > 3.0\n",
        "  predicted_positive = prediction > 2\n",
        "  predicted_negative = prediction < 2\n",
        "\n",
        "  if predicted_positive:\n",
        "    if actually_positive:\n",
        "      true_positives.append(text)\n",
        "    else:\n",
        "      false_positives.append(text)\n",
        "  else:\n",
        "    if predicted_negative:\n",
        "      true_negatives.append(text)\n",
        "    else:\n",
        "      false_negatives.append(text)\n",
        "\n",
        "save_samples('AppsForAndroid_pos_tp.txt', true_positives)\n",
        "save_samples('AppsForAndroid_pos_fp.txt', false_positives)\n",
        "save_samples('AppsForAndroid_neg_tp.txt', true_negatives)\n",
        "save_samples('AppsForAndroid_neg_fp.txt', false_negatives)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09aa1494899a4bac90e67118d9d270e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, max=752937)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e51xS84ohCl9",
        "colab_type": "text"
      },
      "source": [
        "## Task 5 \n",
        "\n",
        "Calculate approximate precision values based on your mapping from task 4.\n",
        "\n",
        "Store the calculations as part of a readme or send the values by e-mail submission. \n",
        "\n",
        "Submit the files from Task 3 and Task 4 as your group submission.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6tvxN1uhCl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88bb2537-7e32-4db0-d973-d84921609d93"
      },
      "source": [
        "print('Precision: ', len(true_positives) / (len(true_positives)+ len(false_positives)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:  0.9248349535449693\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}